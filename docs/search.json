[
  {
    "objectID": "class_notes/week_7.html",
    "href": "class_notes/week_7.html",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "",
    "text": "Look at some ways of adding measurements with lyrics\nNo reading project due on Monday\nCode project due on Wednesday\nSign up for meetings the week of 5/22.\nNO CLASS ON WEDNESDAY\n\n\n## Loading some libraries\nlibrary(tidytext)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(textdata)\nlibrary(DT)"
  },
  {
    "objectID": "class_notes/week_7.html#what-dataset-to-use",
    "href": "class_notes/week_7.html#what-dataset-to-use",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "What dataset to use?",
    "text": "What dataset to use?\nIt’s quite difficult to get lyrics from online sources at the moment. Many of the R interfaces for the Genius API seem to be quite deprecated. Kaggle does have many datasets available, including about 10GB of Genius data. For today, let’s just look at a small dataset of TAylor Swift lyrics."
  },
  {
    "objectID": "class_notes/week_7.html#what-is-tf-idf",
    "href": "class_notes/week_7.html#what-is-tf-idf",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "What is TF-IDF?",
    "text": "What is TF-IDF?\n\ntaylor <- read.csv(\"taylor_swift_lyrics.csv\")\n\nThere’s been some interesting stuff done on lyrics already. We can modify an existing tutorial on Ed Sheeran for today’s discussion.\n\ntaylor_word_count <- taylor %>%\n  unnest_tokens(word, lyric) %>%\n  group_by(track_title, album) %>%\n  summarise(num_words = n()) %>%\n  arrange(desc(num_words)) \n\n`summarise()` has grouped output by 'track_title'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "class_notes/week_7.html#filtering-words",
    "href": "class_notes/week_7.html#filtering-words",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Filtering Words",
    "text": "Filtering Words\nThe anti_join function from the tidyverse basically joins all columns that don’t match something. Here, it’s the words that tidytext has defined has stop words.\n\nwords_filtered <- taylor %>%\n  unnest_tokens(word, lyric) %>%\n  anti_join(stop_words) %>%\n  distinct()\n\nJoining with `by = join_by(word)`"
  },
  {
    "objectID": "class_notes/week_7.html#plotting-the-most-words",
    "href": "class_notes/week_7.html#plotting-the-most-words",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Plotting the most words",
    "text": "Plotting the most words\n\nwords_filtered %>%\n  count(word, sort = TRUE) %>%\n  top_n(30) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot() +\n    geom_col(aes(word, n), fill = 'light blue') +\n    theme(legend.position = \"none\", \n          plot.title = element_text(hjust = 0.5),\n          panel.grid.major = element_blank()) +\n    xlab(\"\") + \n    ylab(\"Song Count\") +\n    ggtitle(\"Most Frequently Used Words in Lyrics\") +\n    coord_flip() +\n     theme_bw()\n\nSelecting by n"
  },
  {
    "objectID": "class_notes/week_7.html#word-counts",
    "href": "class_notes/week_7.html#word-counts",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Word Counts",
    "text": "Word Counts\n\ntaylor_word_count %>%\n  ggplot() +\n    geom_density(aes(x = num_words, fill = album), alpha = 0.5, position = 'stack') +\n    ylab(\"Song Density\") + \n    xlab(\"Word Count per Song\") +\n    ggtitle(\"Word Count Distribution\") +\n    theme(plot.title = element_text(hjust = 0.5),\n          legend.title = element_blank(),\n          panel.grid.minor.y = element_blank()) +\n          theme_bw()\n\n\n\n\n\nWords over Time\nHere we can see the changing word count over time in Taylor Swift’s albums.\n\nwords <- words_filtered %>%\n  group_by(year) %>%\n  count(word, year, sort = TRUE) %>%\n  slice(seq_len(8)) %>%\n  ungroup() %>%\n  arrange(year, n) %>%\n  mutate(row = row_number())\n\nwords %>%\n  ggplot(aes(row, n, fill = year)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Year\") + \n    theme_bw() +  \n    facet_wrap(~year, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_7.html#words-by-album",
    "href": "class_notes/week_7.html#words-by-album",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Words by Album",
    "text": "Words by Album\nThis basically does the same as before, but breaks it down by album and not year.\n\nwords <- words_filtered %>%\n  group_by(album) %>%\n  count(word, album, sort = TRUE) %>%\n  slice(seq_len(8)) %>%\n  ungroup() %>%\n  arrange(album, n) %>%\n  mutate(row = row_number())\n\nwords %>%\n  ggplot(aes(row, n, fill = album)) +\n    geom_col(show.legend = NULL) +\n    labs(x = NULL, y = \"Song Count\") +\n    ggtitle(\"Words Across the Album\") + \n    theme_bw() +  \n    facet_wrap(~album, scales = \"free\") +\n    scale_x_continuous(  # This handles replacement of row \n      breaks = words$row, # notice need to reuse data frame\n      labels = words$word) +\n    coord_flip()\n\nWarning: `show.legend` must be a logical vector."
  },
  {
    "objectID": "class_notes/week_7.html#tf-idf",
    "href": "class_notes/week_7.html#tf-idf",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "TF-IDF",
    "text": "TF-IDF\nWhere it starts to get interesting is when we can begin to employ metrics of frequency in relation to other data points. The Term Infrequency-Inverse Document Frequency (TF-IDF) metric is a good starting point for that.\nBasically, TF-IDF measures not just how often a word occurs, but how often it occurs in relation to other collections. So if there’s a word that occurs everywhere (like “love”), it’s not really weighted as highly.\n\ntfidf_words_album <- taylor %>%\n  unnest_tokens(word, lyric) %>%\n  distinct() %>%\n  count(album, word, sort = TRUE) %>%\n  ungroup() %>%\n  bind_tf_idf(word, album, n) %>%\n  arrange(desc(tf_idf))\n\nThis grabs the top 10 words per album. Notice that the tf_idf metric is simply the product of tf (term frequency) multiplied by idf (inverse document frequency).\n\ntop_tfidf_words_album <- tfidf_words_album %>% \n  group_by(album) %>% \n  slice(seq_len(10)) %>%\n  ungroup() %>%\n  arrange(album, tf_idf) %>%\n  mutate(row = row_number())  \n\ntop_tfidf_words_album\n\n# A tibble: 60 × 7\n   album word           n      tf   idf  tf_idf   row\n   <chr> <chr>      <int>   <dbl> <dbl>   <dbl> <int>\n 1 1989  new           41 0.00699 0.405 0.00283     1\n 2 1989  shake         30 0.00512 0.693 0.00355     2\n 3 1989  clear         19 0.00324 1.10  0.00356     3\n 4 1989  blood         16 0.00273 1.79  0.00489     4\n 5 1989  welcome       27 0.00460 1.10  0.00506     5\n 6 1989  york          27 0.00460 1.10  0.00506     6\n 7 1989  ey            18 0.00307 1.79  0.00550     7\n 8 1989  wonderland    19 0.00324 1.79  0.00580     8\n 9 1989  woods         20 0.00341 1.79  0.00611     9\n10 1989  yet           37 0.00631 1.10  0.00693    10\n# ℹ 50 more rows\n\n\nWe can plot the data like so:\n\ntop_tfidf_words_album %>%\n  ggplot(aes(x = row, tf_idf, fill = album)) +\n  geom_col(show.legend = NULL) +\n  labs(x = NULL, y = \"TF-IDF\") + \n  ggtitle(\"Important Words by Album (as measured by TF-IDF)\") +\n  theme_bw() +  \n  facet_wrap(~album,\n             scales = \"free\") +\n  scale_x_continuous(  # this handles replacement of row \n    breaks = top_tfidf_words_album$row, # notice need to reuse data frame\n    labels = top_tfidf_words_album$word) +\n  coord_flip()\n\nWarning: `show.legend` must be a logical vector.\n\n\n\n\n\n\n## get rid of super rare words.\ntf_idf <- tfidf_words_album %>% filter(tf_idf > .0005)\ntf_idf2 <- as.matrix(tf_idf$tf_idf)\nclustering.kmeans <- stats::kmeans(tf_idf2, centers = 2)\n\n\n\n# Visualize the clustering results using ggplot\ndata <- data.frame(x = tf_idf2[,1], y = tf_idf[,6], lyric = tf_idf$word, label = clustering.kmeans$cluster)\n\n\nggplot(data, aes(x, y, color = factor(label))) + geom_point()"
  },
  {
    "objectID": "class_notes/week_7.html#sentiment-analysis",
    "href": "class_notes/week_7.html#sentiment-analysis",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nWe can then run sentiment analysis on the lyrics after unnesting and getting rid of stop words.\n\ntaylor_words <- taylor %>%\n  ##this breaks the lyrics up into words.\n  unnest_tokens(word, lyric) %>% \n  ## the stop words come from tidytext.\n  anti_join(stop_words) \n\nJoining with `by = join_by(word)`\n\n\nWe will start with the bing classification (named after the PI of the research group, Liu Bing). This classifies words as either positive or negative sentiment. See this PsychStat book for more on these metrics.\n\ntaylor_bing <- taylor_words %>%\n  inner_join(get_sentiments(\"bing\"))\n\nJoining with `by = join_by(word)`\n\n\nWe can also run the nrc word list, which puts words into positive or negative categories, but also uses 8 other emotions, including:\n\nanger\nanticipation\ndisgust\nfear\njoy\nsadness\nsurprise\ntrust\n\nSee the “sentiment” column below in the table. To what extent do we agree with these categories? Do they seem useful to you?\n\ntaylor_nrc <- taylor_words %>%\n  inner_join(get_sentiments(\"nrc\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc %>% datatable(filter =\"top\") \n\n\n\n\n\n\nWe can clean this up by getting rid of the positive and negative emotions, if we’d like:\n\ntaylor_nrc_no_pos_neg <- taylor_words %>%\n  inner_join(get_sentiments(\"nrc\")) %>%\n  filter(!sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_no_pos_neg %>% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can get have only the listing of words rated as “positive” or “negative”.\n\ntaylor_nrc_pos_neg <- taylor_words %>%\n  inner_join(get_sentiments(\"nrc\")) %>%\n  filter(sentiment %in% c(\"positive\", \"negative\"))\n\nJoining with `by = join_by(word)`\n\n\nWarning in inner_join(., get_sentiments(\"nrc\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 6 of `x` matches multiple rows in `y`.\nℹ Row 6230 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntaylor_nrc_pos_neg %>% datatable(filter =\"top\")\n\n\n\n\n\n\nAnd here we can plot everything:\n\nnrc_plot <- taylor_nrc %>%\n  group_by(sentiment) %>%\n  summarise(word_count = n()) %>%\n  ungroup() %>%\n  mutate(sentiment = reorder(sentiment, word_count)) %>%\n  ggplot(aes(sentiment, word_count, fill = -word_count)) +\n  geom_col() +\n  theme_bw() +\n  labs(x = NULL, y = \"Word Count\") +\n  ggtitle(\"NRC Sentiment\") +\n  coord_flip()\nnrc_plot + guides(fill=FALSE)\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nWe can write a function to look at the various sentiments of a tune, which we can then join with other data.\n\nsentiment_calculator <- function(tune){\n  song <- filter(taylor, track_title == tune)\n  song_word <- song %>% unnest_tokens(word, lyric)\n  song_sentiment <- song_word %>% \n    inner_join(get_sentiments(\"nrc\"), relationship = \"many-to-many\") %>% \n    count(track_title, index = line %/% 100, sentiment) %>%\n    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) \n    return(song_sentiment)\n}\n\nsentiment_calculator(\"Bad Blood\")\n\nJoining with `by = join_by(word)`\n\n\n# A tibble: 1 × 12\n  track_title index anger anticipation disgust  fear   joy negative positive\n  <chr>       <dbl> <int>        <int>   <int> <int> <int>    <int>    <int>\n1 Bad Blood       0    22            3      20    22    27       24       27\n# ℹ 3 more variables: sadness <int>, surprise <int>, trust <int>\n\n# taylor %>% group_by(track_title) %>% nest() %>%\n#   map(., ~ sentiment_calculator(.))"
  },
  {
    "objectID": "class_notes/week_7.html#blur-and-oasis",
    "href": "class_notes/week_7.html#blur-and-oasis",
    "title": "Week 7: Text, TF-IDF, etc.",
    "section": "Blur and Oasis",
    "text": "Blur and Oasis\nThis data is taken from the “Million Song Dataset” from Spotify.\n\noasis <- read.csv(\"oasis.csv\")\nblur <- read.csv(\"blur.csv\")\n\nAnd we can begin getting words like this:\n\noasis_words <- oasis %>%\n  unnest_tokens(word, text) %>%\n  anti_join(stop_words) %>%\n  distinct()\n\nContinuing with a summary like so…\n\nfull_word_count <- oasis %>%\n  unnest_tokens(word, text) %>%\n  group_by(track_title) %>%\n  summarise(num_words = n()) %>%\n  arrange(desc(num_words))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Corpus Studies and Music",
    "section": "",
    "text": "Welcome!\nWelcome to the Corpus Studies and Music class."
  }
]